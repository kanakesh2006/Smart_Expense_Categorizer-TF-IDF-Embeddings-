{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOl4DnUqRMleH0IJYHYCPym",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kanakesh2006/Smart_Expense_Categorizer_TF-IDF_and_Embeddings/blob/main/Smart_Expense_Categorizer_using_TF_IDF_Vectorizer_Embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sc7hJ1vSfjZe"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import re\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Data Generation**"
      ],
      "metadata": {
        "id": "hMW3suNThLak"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "categories = {\n",
        "    'Food': ['SWIGGY', 'ZOMATO', 'DOMINOS', 'CAFE COFFEE DAY', 'STARBUCKS', 'RESTAURANT', 'PIZZA HUT'],\n",
        "    'Travel': ['UBER', 'OLA', 'METRO CARD RECHARGE', 'INDIAN RAILWAYS', 'PETROL PUMP', 'FLIGHT TICKET'],\n",
        "    'Groceries': ['GROFER', 'BIGBASKET', 'RELIANCE FRESH', 'SUPERMARKET', 'DAILY NEEDS'],\n",
        "    'Shopping': ['AMAZON', 'FLIPKART', 'MYNTRA', 'SHOE STORE', 'ELECTRONICS'],\n",
        "    'Utilities': ['ELECTRICITY BILL', 'MOBILE RECHARGE', 'BROADBAND BILL', 'WATER SUPPLY'],\n",
        "    'Entertainment': ['NETFLIX', 'PVR CINEMAS', 'BOOKMYSHOW', 'SPOTIFY', 'GAME PASS']\n",
        "}\n",
        "\n",
        "data = []\n",
        "for category, merchants in categories.items():\n",
        "    for merchant in merchants:\n",
        "        for _ in range(50): # generate 50 samples per merchant\n",
        "            # generate a random amount between 50 and 5000\n",
        "            amount = random.randint(50, 5000)\n",
        "            # Create the transaction text\n",
        "            transaction_text = f\"TXN SUCCESSFUL FOR {amount} AT {merchant} VIA DEBIT CARD XXXX\"\n",
        "            data.append({'Transaction_Text': transaction_text, 'Category': category})\n",
        "\n",
        "df = pd.DataFrame(data)"
      ],
      "metadata": {
        "id": "vepu7CeOgy5B"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Generated Data Samples:\")\n",
        "print(df.head())\n",
        "print(\"\\nCategory Distribution:\")\n",
        "print(df['Category'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yw9AMfE5g6va",
        "outputId": "69936d11-d66e-443e-acbd-5caf1d606f6b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Data Samples:\n",
            "                                    Transaction_Text Category\n",
            "0  TXN SUCCESSFUL FOR 4158 AT SWIGGY VIA DEBIT CA...     Food\n",
            "1  TXN SUCCESSFUL FOR 4209 AT SWIGGY VIA DEBIT CA...     Food\n",
            "2  TXN SUCCESSFUL FOR 4132 AT SWIGGY VIA DEBIT CA...     Food\n",
            "3  TXN SUCCESSFUL FOR 3230 AT SWIGGY VIA DEBIT CA...     Food\n",
            "4  TXN SUCCESSFUL FOR 4838 AT SWIGGY VIA DEBIT CA...     Food\n",
            "\n",
            "Category Distribution:\n",
            "Category\n",
            "Food             350\n",
            "Travel           300\n",
            "Groceries        250\n",
            "Shopping         250\n",
            "Entertainment    250\n",
            "Utilities        200\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Data Preprocesing**"
      ],
      "metadata": {
        "id": "Y4S3r-lShr51"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean the text (e.g., removing 'TXN SUCCESSFUL FOR', 'VIA DEBIT CARD XXXX')\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'(txn successful for|via debit card xxxx|at|for|a/c|ref|debit|credit)', '', text)\n",
        "    text = re.sub(r'\\d+', ' ', text) # Remove numbers (amounts), as we want the model to rely on merchant names\n",
        "    return text.strip()\n",
        "\n",
        "df['Cleaned_Text'] = df['Transaction_Text'].apply(clean_text)\n",
        "\n",
        "# Split the data\n",
        "X = df['Cleaned_Text']\n",
        "y = df['Category']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n"
      ],
      "metadata": {
        "id": "fl1-pswfgFSI"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **TF-IDF Vectorizer**"
      ],
      "metadata": {
        "id": "_dnf8Ovpg8bw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TF-IDF + Logistic Regression\n",
        "\n",
        "# Feature Extraction (TF-IDF)\n",
        "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2), max_features=5000)\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
        "\n",
        "print(f\"\\nTF-IDF Matrix Shape: {X_train_tfidf.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IC_qEw49hov5",
        "outputId": "ac87b2ae-a0c9-442e-a4d6-23e67acf9944"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TF-IDF Matrix Shape: (1280, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Training\n",
        "lr_model = LogisticRegression(max_iter=1000, random_state=42)\n",
        "lr_model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "y_pred_lr = lr_model.predict(X_test_tfidf)\n",
        "\n",
        "print(\"\\n TF-IDF + Logistic Regression Results : \")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_lr):.4f}\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_lr))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfzCc5OZi5BW",
        "outputId": "bb37120a-c9a3-480d-bde5-b449193786ad"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " TF-IDF + Logistic Regression Results : \n",
            "Accuracy: 1.0000\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "Entertainment       1.00      1.00      1.00        50\n",
            "         Food       1.00      1.00      1.00        70\n",
            "    Groceries       1.00      1.00      1.00        50\n",
            "     Shopping       1.00      1.00      1.00        50\n",
            "       Travel       1.00      1.00      1.00        60\n",
            "    Utilities       1.00      1.00      1.00        40\n",
            "\n",
            "     accuracy                           1.00       320\n",
            "    macro avg       1.00      1.00      1.00       320\n",
            " weighted avg       1.00      1.00      1.00       320\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction Test\n",
        "test_transaction = [\"txn for 450 at PIZZA HUT\", \"txn for 2500 at FLIPKART\"]\n",
        "test_cleaned = [clean_text(t) for t in test_transaction]\n",
        "test_tfidf = tfidf_vectorizer.transform(test_cleaned)\n",
        "predictions = lr_model.predict(test_tfidf)\n",
        "\n",
        "print(\"\\nPrediction Test:\")\n",
        "for text, pred in zip(test_transaction, predictions):\n",
        "    print(f\"Text: '{text}' -> Predicted Category: {pred}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNYsc_GDjmBB",
        "outputId": "b1705e33-dd2c-4501-ad6e-f510c177bc7a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Prediction Test:\n",
            "Text: 'txn for 450 at PIZZA HUT' -> Predicted Category: Food\n",
            "Text: 'txn for 2500 at FLIPKART' -> Predicted Category: Shopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Embeddings**"
      ],
      "metadata": {
        "id": "rGU6lhvrhSJb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Embeddings (Neural Network)\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Flatten, Dense\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "ctXtdcC5gI4i"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert labels to numerical format\n",
        "le = LabelEncoder()\n",
        "y_train_encoded = le.fit_transform(y_train)\n",
        "y_test_encoded = le.transform(y_test)\n",
        "num_classes = len(le.classes_)\n"
      ],
      "metadata": {
        "id": "4YT-hTg3kHZc"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization and Padding\n",
        "max_words = 1000 # Max number of words to keep\n",
        "tokenizer = Tokenizer(num_words=max_words, oov_token=\"<unk>\")\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "maxlen = max(len(x) for x in X_train_seq) # Max length of a sequence\n",
        "X_train_pad = pad_sequences(X_train_seq, maxlen=maxlen, padding='post')\n",
        "X_test_pad = pad_sequences(X_test_seq, maxlen=maxlen, padding='post')\n",
        "\n",
        "print(f\"Max Sequence Length: {maxlen}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhaGRQ4okPbn",
        "outputId": "c2b92e52-f2fb-4dad-d921-2e26b0de2f5a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max Sequence Length: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Architecture\n",
        "embedding_dim = 100 # Size of the word vectors\n",
        "model = Sequential([\n",
        "    Embedding(max_words, embedding_dim, input_length=maxlen),\n",
        "    Flatten(),\n",
        "    Dense(10, activation='relu'),\n",
        "    Dense(num_classes, activation='softmax') # multi-class classification\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy', # Use sparse if labels are integers\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZeXH1clekWrg",
        "outputId": "2792f545-97da-46b6-8ef1-cb5135b568d0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Training\n",
        "print(\"\\n--- Training Embedding Model ---\")\n",
        "history = model.fit(X_train_pad, y_train_encoded,\n",
        "                    epochs=10,\n",
        "                    verbose=0, # Set to 1 for real training\n",
        "                    validation_data=(X_test_pad, y_test_encoded))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-t28ewtckmBy",
        "outputId": "7a4642a6-583a-4e75-e81f-c0503ca35bb5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Training Embedding Model ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation\n",
        "loss, acc = model.evaluate(X_test_pad, y_test_encoded, verbose=0)\n",
        "print(f\"\\n--- Simple Embedding Model (NN) Results ---\")\n",
        "print(f\"Test Accuracy: {acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHXvWokskoqU",
        "outputId": "51eb6bcc-5a79-4176-ae12-5635e641aa62"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Simple Embedding Model (NN) Results ---\n",
            "Test Accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction Test\n",
        "test_seq = tokenizer.texts_to_sequences([clean_text(t) for t in test_transaction])\n",
        "test_pad = pad_sequences(test_seq, maxlen=maxlen, padding='post')\n",
        "predictions_nn_prob = model.predict(test_pad)\n",
        "predictions_nn = np.argmax(predictions_nn_prob, axis=1)\n",
        "predicted_categories_nn = le.inverse_transform(predictions_nn)\n",
        "\n",
        "print(\"\\nPrediction Test (NN):\")\n",
        "for text, pred in zip(test_transaction, predicted_categories_nn):\n",
        "    print(f\"Text: '{text}' -> Predicted Category: {pred}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yz_6gN5kr86",
        "outputId": "dc6a5ee9-8645-407c-da12-7a8661f19743"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step\n",
            "\n",
            "Prediction Test (NN):\n",
            "Text: 'txn for 450 at PIZZA HUT' -> Predicted Category: Food\n",
            "Text: 'txn for 2500 at FLIPKART' -> Predicted Category: Groceries\n"
          ]
        }
      ]
    }
  ]
}